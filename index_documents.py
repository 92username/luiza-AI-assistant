import os
"""
Este script indexa documentos Markdown para um sistema de recupera√ß√£o de texto usando Langchain e OpenAI.

O processo inclui:
1. Carregamento de documentos Markdown do diret√≥rio ./docs
2. Fragmenta√ß√£o dos documentos em chunks menores para processamento eficiente
3. Gera√ß√£o de embeddings usando a API da OpenAI
4. Armazenamento dos embeddings no Chroma Vector Database

Depend√™ncias:
- langchain
- openai
- chromadb
- python-dotenv

Requisitos:
- Arquivo .env com a vari√°vel OPENAI_API_KEY definida
- Diret√≥rio ./docs com arquivos Markdown (.md) para indexa√ß√£o

Uso:
    $ python index_documents.py

Sa√≠da:
    Os embeddings s√£o armazenados no diret√≥rio ./chroma_index
"""
from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader # Updated import
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma # Updated import
from langchain_openai import OpenAIEmbeddings # Updated import
from pydantic import SecretStr # Added import

# Carregar vari√°veis do .env
load_dotenv()

# Verificar se a API KEY est√° dispon√≠vel
api_key_str = os.getenv("OPENAI_API_KEY")
if not api_key_str:
    raise EnvironmentError("Vari√°vel OPENAI_API_KEY n√£o encontrada. Verifique seu .env.")
api_key_secret = SecretStr(api_key_str) # Use SecretStr

if __name__ == "__main__":
    # Carregar documentos da pasta /docs
    docs_path = "./docs"
    if not os.path.exists(docs_path):
        raise FileNotFoundError("Pasta ./docs n√£o encontrada. Crie a pasta e adicione arquivos .md.")

    print("üìÑ Carregando arquivos Markdown...")
    # 1.1 Carrega todos os .md de /docs
    loader = DirectoryLoader(docs_path, glob="*.md")
    raw_documents = loader.load()

    # Dividir os textos em peda√ßos menores
    print(f"üìÉ {len(raw_documents)} documentos carregados. Fragmentando...")
    # 1.2 Configura o splitter
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=100,
        separators=["\\n\\n", "\\n", ".", " "]
    )
    # 1.3 Gera os chunks
    documents = text_splitter.split_documents(raw_documents)

    # 2. Atribuir ‚Äútema‚Äù com base no nome do arquivo
    print("üè∑Ô∏è Atribuindo metadados 'tema'...")
    for doc in documents:
        src = doc.metadata["source"]  # ex: "docs/03-proposta-de-valor-e-mvp.md"
        filename = os.path.basename(src) # ex: "03-proposta-de-valor-e-mvp.md"
        if filename.startswith("01-"):
            doc.metadata["tema"] = "visao-geral"
        elif filename.startswith("02-"):
            doc.metadata["tema"] = "plataforma"
        elif filename.startswith("03-"):
            doc.metadata["tema"] = "mvp"
        elif filename.startswith("04-"):
            doc.metadata["tema"] = "comecar"
        elif filename.startswith("05-"):
            doc.metadata["tema"] = "fontes"
        else:
            doc.metadata["tema"] = None


    # Criar os embeddings e armazenar no Chroma
    print("üß† Gerando embeddings com OpenAI...")
    # 3.1 Cria embeddings
    embedding = OpenAIEmbeddings(api_key=api_key_secret, model="text-embedding-ada-002") # Updated model and use SecretStr

    print("üì¶ Persistindo √≠ndice no diret√≥rio ./chroma_db ...")
    # 3.2 Monta o Chroma
    vectordb = Chroma.from_documents(
        documents=documents,
        embedding=embedding,
        persist_directory="./chroma_db"
    )
    # 3.3 Persiste em disco
    vectordb.persist()

    print("‚úÖ √çndice criado com sucesso!")
