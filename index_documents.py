
import os
"""
Este script indexa documentos Markdown para um sistema de recupera√ß√£o de texto usando Langchain e OpenAI.

O processo inclui:
1. Carregamento de documentos Markdown do diret√≥rio ./docs
2. Fragmenta√ß√£o dos documentos em chunks menores para processamento eficiente
3. Gera√ß√£o de embeddings usando a API da OpenAI
4. Armazenamento dos embeddings no Chroma Vector Database

Depend√™ncias:
- langchain
- openai
- chromadb
- python-dotenv

Requisitos:
- Arquivo .env com a vari√°vel OPENAI_API_KEY definida
- Diret√≥rio ./docs com arquivos Markdown (.md) para indexa√ß√£o

Uso:
    $ python index_documents.py

Sa√≠da:
    Os embeddings s√£o armazenados no diret√≥rio ./chroma_index
"""
from dotenv import load_dotenv
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# Carregar vari√°veis do .env
load_dotenv()

# Verificar se a API KEY est√° dispon√≠vel
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise EnvironmentError("Vari√°vel OPENAI_API_KEY n√£o encontrada. Verifique seu .env.")

# Carregar documentos da pasta /docs
docs_path = "./docs"
if not os.path.exists(docs_path):
    raise FileNotFoundError("Pasta ./docs n√£o encontrada. Crie a pasta e adicione arquivos .md.")

print("üìÑ Carregando arquivos Markdown...")
loader = DirectoryLoader(docs_path, glob="**/*.md")
raw_documents = loader.load()

# Dividir os textos em peda√ßos menores
print(f"üìÉ {len(raw_documents)} documentos carregados. Fragmentando...")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
documents = text_splitter.split_documents(raw_documents)

# Criar os embeddings e armazenar no Chroma
print("üß† Gerando embeddings com OpenAI...")
embedding = OpenAIEmbeddings(api_key=api_key)

print("üì¶ Persistindo √≠ndice no diret√≥rio ./chroma_index ...")
vectordb = Chroma.from_documents(documents, embedding, persist_directory="./chroma_index")
vectordb.persist()

print("‚úÖ √çndice criado com sucesso!")
